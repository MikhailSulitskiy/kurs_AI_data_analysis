# -*- coding: utf-8 -*-
"""СулицкийМВ_Курсовая работа_Candy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TqC8fFu1ht9ZPopIop6Gk7G_Cv_0-BWn
"""

import numpy as np
import pandas as pd 
import statsmodels.api as sm
import statsmodels.formula.api as smf
import seaborn as sns
from sklearn.preprocessing import scale 
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.metrics import roc_auc_score,roc_curve
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier

from warnings import filterwarnings
filterwarnings('ignore')

import os

candy_data = pd.read_csv("/content/candy-data.csv")

candy_data.head(2)

candy_data.info()

candy_data.describe().T

# Давайте посмотрим 0, 1 количество шоколада в виде батончика
candy_data['chocolate'].value_counts().plot.barh();

# функция "competitorname" нам не нужна, ее отбросим
candy_data.drop("competitorname", inplace = True, axis=1)

y = candy_data.chocolate.values
X = candy_data.drop(["chocolate"], axis = 1)

# посмотрим, сколько нулевых значений у нас есть, мб нам не нужно нормализовать

candy_data.isnull().sum()

"""#Логистическая регрессия"""

loj = LogisticRegression(solver = "liblinear")
loj_model = loj.fit(X,y)
loj_model

loj_model.intercept_      # константа
loj_model.coef_           # независимые

y_pred = loj_model.predict(X)        # прогноз
confusion_matrix(y, y_pred)          # матрица неточностей

accuracy_score(y, y_pred)

print(classification_report(y, y_pred))

# модель прогзноща
loj_model.predict(X)[0:20]

loj_model.predict_proba(X)[0:10][:,0:2]

# Теперь давайте попробуем смоделировать вероятность "predict_proba" 

y_probs = loj_model.predict_proba(X)
y_probs = y_probs[:,1]
y_probs[0:20]

# giving limit for values

y_pred = [1 if i > 0.5 else 0 for i in y_probs]

# и сравним с вышеизложенным, мы сможем увидеть что произошло
y_pred[0:20]

confusion_matrix(y, y_pred)

accuracy_score(y, y_pred)

print(classification_report(y, y_pred))

logit_roc_auc = roc_auc_score(y, loj_model.predict(X))

fpr, tpr, thresholds = roc_curve(y, loj_model.predict_proba(X)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Ложноположительная Оценка')
plt.ylabel('Истинная Положительная Оценка')
plt.title('ROC')
plt.show()

# blue line: который мы задаем нашей моделью
# red line: если мы этого не сделаем, что может быть в результате

X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    test_size = 0.30, 
                                                    random_state = 42)

loj = LogisticRegression(solver = "liblinear")
loj_model = loj.fit(X_train,y_train)
loj_model

accuracy_score(y_test, loj_model.predict(X_test))

# с кросс-валидацией

cross_val_score(loj_model, X_test, y_test, cv = 10).mean()

"""#Наивный байессовский """

nb = GaussianNB()
nb_model = nb.fit(X_train, y_train)
nb_model

nb_model.predict(X_test)[0:10]

nb_model.predict_proba(X_test)[0:10]

# predict
y_pred = nb_model.predict(X_test)

accuracy_score(y_test, y_pred)

cross_val_score(nb_model, X_test, y_test, cv = 10).mean()